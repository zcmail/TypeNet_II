{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.4901962e-01  1.3200000e-01  8.8700002e-01  1.0190001e+00\n",
      "  1.0191320e+00  7.3333335e-01  1.5899999e-01  3.7500000e-01\n",
      "  5.3399998e-01  5.3415900e-01  6.2745094e-02  4.6700001e-01\n",
      " -2.0800000e-01  2.5900000e-01  2.5946701e-01  3.4901962e-01\n",
      "  1.4600000e-01  1.0900000e-01  2.5500000e-01  2.5514600e-01\n",
      "  3.0980393e-01  2.3199999e-01 -4.3000001e-02  1.8900000e-01\n",
      "  1.8923201e-01  3.3333334e-01  1.2000000e-01  5.6300002e-01\n",
      "  6.8300003e-01  6.8312001e-01  7.3333335e-01  5.6000002e-02\n",
      "  1.4500000e-01  2.0100001e-01  2.0105600e-01  3.1372547e-02\n",
      "  3.2000002e-02  1.3200000e-01  1.6400000e-01  1.6403200e-01\n",
      "  7.3333335e-01  5.9000000e-02  1.1800000e-01  1.7700000e-01\n",
      "  1.7705899e-01  3.1372547e-02  9.4999999e-02  7.8000002e-02\n",
      "  1.7299999e-01  1.7309500e-01  3.1372547e-02  8.7800002e-01\n",
      "  1.0000000e-03  8.7900001e-01  8.7987798e-01  6.2745094e-02\n",
      "  6.6200000e-01 -2.1200000e-01  4.4999999e-01  4.5066199e-01\n",
      "  3.4901962e-01  1.4300001e-01  1.6200000e-01  3.0500001e-01\n",
      "  3.0514300e-01  3.0980393e-01  2.1100000e-01  0.0000000e+00\n",
      "  2.1100000e-01  2.1121100e-01  3.3333334e-01  1.1100000e-01\n",
      "  3.2200000e-01  4.3300000e-01  4.3311101e-01  1.2549020e-01\n",
      "  1.4200000e-01  3.5499999e-01  4.9700001e-01  4.9714199e-01\n",
      "  2.6274511e-01  3.2900000e-01  1.4100000e-01  4.7000000e-01\n",
      "  4.7032899e-01  2.5490198e-01  2.3300000e-01  2.4000000e-02\n",
      "  2.5700000e-01  2.5723299e-01  3.0588236e-01  1.5099999e-01\n",
      "  4.6999998e-02  1.9800000e-01  1.9815101e-01  1.2549020e-01\n",
      "  1.5400000e-01  7.2999999e-02  2.2700000e-01  2.2715400e-01\n",
      "  2.5882354e-01  1.2800001e-01  6.3000001e-02  1.9100000e-01\n",
      "  1.9112800e-01  3.2156864e-01  9.0000004e-02  4.6999998e-02\n",
      "  1.3699999e-01  1.3709000e-01  2.8627452e-01  9.7999997e-02\n",
      "  2.5000000e-01  3.4799999e-01  3.4809801e-01  3.0588236e-01\n",
      "  1.0000000e-01  1.2500000e-01  2.2499999e-01  2.2510000e-01\n",
      "  2.7843139e-01  1.0600000e-01  9.3999997e-02  2.0000000e-01\n",
      "  2.0010599e-01  1.2549020e-01  1.2700000e-01  2.8099999e-01\n",
      "  4.0799999e-01  4.0812701e-01  2.8627452e-01  1.3500001e-01\n",
      "  2.0299999e-01  3.3800000e-01  3.3813500e-01  3.2941177e-01\n",
      "  9.7999997e-02  0.0000000e+00  9.7999997e-02  9.8098002e-02\n",
      "  1.2549020e-01  1.3300000e-01  3.0999999e-02  1.6400000e-01\n",
      "  1.6413300e-01  3.0980393e-01  1.6200000e-01  2.7000001e-02\n",
      "  1.8900000e-01  1.8916200e-01  3.2941177e-01  8.2000002e-02\n",
      "  3.0999999e-02  1.1300000e-01  1.1308200e-01  1.2549020e-01\n",
      "  1.5600000e-01  3.1099999e-01  4.6700001e-01  4.6715599e-01\n",
      "  3.4117648e-01  2.4200000e-01  1.7200001e-01  4.1400000e-01\n",
      "  4.1424200e-01  3.0980393e-01  1.3300000e-01  4.6999998e-02\n",
      "  1.8000001e-01  1.8013300e-01  3.2156864e-01  1.2600000e-01\n",
      "  5.7999998e-02  1.8400000e-01  1.8412600e-01  2.9411766e-01\n",
      "  1.3800000e-01  1.2500000e-01  2.6300001e-01  2.6313800e-01\n",
      "  1.2549020e-01  1.1000000e-01  3.2800001e-01  4.3799999e-01\n",
      "  4.3810999e-01  2.5490198e-01  3.6399999e-01  6.3200003e-01\n",
      "  9.9599999e-01  9.9636400e-01  3.0588236e-01  9.3999997e-02\n",
      "  6.1999999e-02  1.5600000e-01  1.5609400e-01  2.6666668e-01\n",
      "  1.2000000e-01  2.5000000e-02  1.4500000e-01  1.4511999e-01\n",
      "  1.2549020e-01  1.5200000e-01  7.8000002e-02  2.3000000e-01\n",
      "  2.3015200e-01  3.4117648e-01  2.0299999e-01 -5.0000001e-02\n",
      "  1.5300000e-01  1.5320300e-01  2.7058825e-01  1.3800000e-01\n",
      "  4.6999998e-02  1.8500000e-01  1.8513800e-01  1.2549020e-01\n",
      "  1.1800000e-01  2.8799999e-01  4.0599999e-01  4.0611801e-01\n",
      "  2.6274511e-01  1.7900001e-01  5.7000000e-02  2.3600000e-01\n",
      "  2.3617899e-01  3.0980393e-01  1.4600000e-01  6.1999999e-02\n",
      "  2.0800000e-01  2.0814601e-01  3.3333334e-01  1.6900000e-01\n",
      "  6.1999999e-02  2.3100001e-01  2.3116900e-01  2.9803923e-01\n",
      "  1.9800000e-01  2.5000000e-02  2.2300000e-01  2.2319800e-01\n",
      "  2.6666668e-01  8.8000000e-02  3.0999999e-02  1.1900000e-01\n",
      "  1.1908800e-01  1.2549020e-01  1.4800000e-01  2.5000000e-02\n",
      "  1.7299999e-01  1.7314801e-01  3.0588236e-01  1.2200000e-01\n",
      "  3.2800001e-01  4.4999999e-01  4.5012200e-01  3.1372547e-02\n",
      "  9.4999999e-02  2.5000000e-01  3.4500000e-01  3.4509501e-01\n",
      "  3.0196080e-01  8.3999999e-02  6.1999999e-02  1.4600000e-01\n",
      "  1.4608400e-01  2.7058825e-01  8.6999997e-02  9.3999997e-02\n",
      "  1.8099999e-01  1.8108700e-01  2.7058825e-01  1.5099999e-01\n",
      "  0.0000000e+00  1.5099999e-01  1.5115100e-01  3.2941177e-01\n",
      "  5.7000000e-02  9.3999997e-02  1.5099999e-01  1.5105700e-01\n",
      "  1.2549020e-01  1.3400000e-01  5.9700000e-01  7.3100001e-01\n",
      "  7.3113400e-01  2.7450982e-01  3.0300000e-01 -1.5400000e-01\n",
      "  1.4900000e-01  1.4930300e-01  3.0980393e-01  1.5400000e-01\n",
      "  0.0000000e+00  1.5400000e-01  1.5415400e-01  3.2156864e-01\n",
      "  8.8000000e-02  1.5000000e-02  1.0300000e-01  1.0308800e-01\n",
      "  1.2549020e-01  1.9599999e-01  4.1999999e-02  2.3800001e-01\n",
      "  2.3819600e-01  2.9803923e-01  1.7299999e-01  3.0999999e-02\n",
      "  2.0400000e-01  2.0417300e-01  3.3333334e-01  1.0400000e-01\n",
      "  4.0700001e-01  5.1099998e-01  5.1110399e-01  3.0588236e-01\n",
      "  8.2000002e-02  2.9100001e-01  3.7300000e-01  3.7308201e-01\n",
      "  2.6274511e-01  1.5400000e-01  0.0000000e+00  1.5400000e-01\n",
      "  1.5415400e-01  2.8235295e-01  7.1999997e-02  1.2400000e-01\n",
      "  1.9599999e-01  1.9607200e-01  1.2549020e-01  9.0999998e-02\n",
      "  5.9500003e-01  6.8599999e-01  6.8609101e-01  3.0980393e-01\n",
      "  1.6700000e-01  1.5600000e-01  3.2300001e-01  3.2316700e-01\n",
      "  3.0588236e-01  1.1300000e-01  3.0999999e-02  1.4399999e-01\n",
      "  1.4411300e-01  2.7058825e-01  1.0400000e-01  7.8000002e-02\n",
      "  1.8200000e-01  1.8210401e-01]\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 70, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 70, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 64)           76884       input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 64)           0           model[1][0]                      \n",
      "                                                                 model[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            65          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 81,109\n",
      "Trainable params: 81,099\n",
      "Non-trainable params: 10\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "\"\"\"LSTM_Keystroke_Similarity\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import keras.backend as K\n",
    "#import keras.utils as ku\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.embeddings import *\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.optimizers import Adam\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from tensorflow.keras.utils import multi_gpu_model\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "# Global Variables\n",
    "HID_DIM = 128\n",
    "SQUENCE_NUM = 70\n",
    "VECTOR_UNIT = 5\n",
    "VECTOR_LEN = SQUENCE_NUM * VECTOR_UNIT\n",
    "\n",
    "# Create pairs\n",
    "def create_pairs(df):\n",
    "    all_pairs_list = []\n",
    "    user_list = df['user'].unique().tolist()\n",
    "    user_num = len(user_list)\n",
    "    #print('user_num:',user_num)\n",
    "    \n",
    "    colum_list = ['user_left','index_left','user_right','index_right']\n",
    "    df_makeData_all = pd.DataFrame(columns = colum_list)\n",
    "\n",
    "    for j, u in enumerate(user_list):  # 遍历所有用户\n",
    "        df_user = df[df['user'] == u]\n",
    "        df_user_len = len(df_user)\n",
    "        # print('user',u)\n",
    "        for i in range(df_user_len):\n",
    "            same_pair_list = []\n",
    "            diff_pair_list = []\n",
    "\n",
    "            #df_user.sample(frac=1).reset_index(drop=True)  # 打乱用户样本顺序\n",
    "            z1, z2 = sum(df_user.iloc[i, 2], []), sum(df_user.iloc[(i + 1) % df_user_len, 2], [])  # 同一用户样本\n",
    "            if any(x is None for x in z1) or any(x is None for x in z2) :\n",
    "                continue             \n",
    "            \n",
    "            same_pair_list.append(z1)\n",
    "            same_pair_list.append(z2)\n",
    "            same_pair_list.append(0.0)  # 同一用户样本标识0\n",
    "            all_pairs_list.append(same_pair_list)            \n",
    "            df_makeData_all=df_makeData_all.append(pd.DataFrame({'user_left':[u],'index_left':[i],'user_right':[u],'index_right':[(i + 1) % df_user_len]}),ignore_index=True)\n",
    "            \n",
    "            inc = 1\n",
    "            dn = (j + inc) % (user_num-1)  # 不同用户样本\n",
    "            if dn != j:\n",
    "                diff_user = user_list[dn]\n",
    "            else:\n",
    "                diff_user = user_list[(dn + 1) % (user_num-1)]\n",
    "            # print('diff',diff_user)\n",
    "            df_diff_user = df[df['user'] == diff_user]\n",
    "            diff_user_len = len(df_diff_user)\n",
    "            if diff_user_len == 0:\n",
    "                '''\n",
    "                print('dn:',dn)\n",
    "                print('diff_user:',diff_user)\n",
    "                print('user_list:',user_list[dn])\n",
    "                print('user_list_all:',user_list)\n",
    "                print('user_list_len:', len(user_list))\n",
    "                print('df_diff_user:',df_diff_user)\n",
    "                '''\n",
    "                continue\n",
    "            z3, z4 = sum(df_user.iloc[i, 2], []), sum(df_diff_user.iloc[i % diff_user_len, 2], [])\n",
    "            if any(x is None for x in z3) or any(x is None for x in z4) :\n",
    "                continue          \n",
    "            diff_pair_list.append(z3)\n",
    "            diff_pair_list.append(z4)\n",
    "            diff_pair_list.append(1.0)  # 不同用户样本标识1.0\n",
    "            all_pairs_list.append(diff_pair_list)\n",
    "            \n",
    "            df_makeData_all=df_makeData_all.append(pd.DataFrame({'user_left':[u],'index_left':[i],'user_right':[diff_user],'index_right':[i % diff_user_len]}),ignore_index=True)\n",
    "\n",
    "        if j >= 10000:\n",
    "            break            \n",
    "            \n",
    "    return all_pairs_list,df_makeData_all\n",
    "\n",
    "def process_data(pairs):\n",
    "    keystroke1_data_list = []\n",
    "    keystroke2_data_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(pairs)):\n",
    "        keystroke1_data = pad_sequences([pairs[i][0]], maxlen=VECTOR_LEN, dtype='float32', padding='post',\n",
    "                                        truncating='post')\n",
    "        keystroke2_data = pad_sequences([pairs[i][1]], maxlen=VECTOR_LEN, dtype='float32', padding='post',\n",
    "                                        truncating='post')\n",
    "        label = pairs[i][2]\n",
    "        judge_nan_left = np.array(keystroke1_data[0])\n",
    "        judge_nan_right = np.array(keystroke2_data[0])\n",
    "        if np.any(np.isnan(judge_nan_left)) or np.any(np.isnan(judge_nan_right)):\n",
    "            #print('judge_nan_left',judge_nan_left)\n",
    "            #print('judge_nan_right',judge_nan_right)\n",
    "            continue\n",
    "        keystroke1_data_list.append(keystroke1_data[0])\n",
    "        keystroke2_data_list.append(keystroke2_data[0])\n",
    "        label_list.append(label)\n",
    "        if np.any(np.isnan(judge_nan_left)):\n",
    "            print('zc_nan')\n",
    "    return np.array(keystroke1_data_list), np.array(keystroke2_data_list), np.array(label_list)\n",
    "\n",
    "def accuracy(y_true, y_pred):  # Tensor上的操作\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred > 0.5, y_true.dtype)))\n",
    "\n",
    "\n",
    "def plot_train_history(history, train_metrics, val_metrics):\n",
    "    plt.plot(history.history.get(train_metrics), '-o')\n",
    "    plt.plot(history.history.get(val_metrics), '-o')\n",
    "    plt.ylabel(train_metrics)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['train', 'validation'])\n",
    "\n",
    "def create_base_network(dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=(SQUENCE_NUM, VECTOR_UNIT))\n",
    "    mask = Masking(0)(input)\n",
    "    bn_layer1 = BatchNormalization(name='bn_layer1')(mask)\n",
    "    lstm_1 = LSTM(dim, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n",
    "                  return_sequences=False, name='lstm_layer1', recurrent_dropout=0.2)\n",
    "    lstm_layer1 = lstm_1(bn_layer1)\n",
    "    #Dropout(lstm_layer1, 0.5)\n",
    "    dense_out = Dense(64, activation= 'relu', input_dim= 128, use_bias= True)(lstm_layer1)\n",
    "    #Dropout(lstm_layer1, 0.5)\n",
    "    #bn_layer2 = BatchNormalization(name='bn_layer2_input1')(lstm_layer1)\n",
    "    #lstm_2 = LSTM(dim, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n",
    "    #              return_sequences=False, name='lstm_layer2', recurrent_dropout=0.2)\n",
    "    #lstm_layer2 = lstm_2(bn_layer2)\n",
    "\n",
    "\n",
    "    return Model(input, dense_out)\n",
    "\n",
    "#file_name = './train_five_tuple_vector_data.json'\n",
    "#file_name = './five_tuple_vector_data.json'\n",
    "file_name = './test_five_tuple_vector_data_del_null.json'\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "\n",
    "df = pd.read_json(file_name)\n",
    "df = df.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "colum_list = ['user_left','index_left','user_right','index_right']\n",
    "new_dataFrame = pd.DataFrame(columns = colum_list)\n",
    "\n",
    "data_pairs, new_dataFrame = create_pairs(df)\n",
    "left,right,label = process_data(data_pairs)\n",
    "print(left[0])\n",
    "\n",
    "num = left.shape[0]\n",
    "\n",
    "left = left.reshape(num,SQUENCE_NUM,VECTOR_UNIT)\n",
    "right = right.reshape(num,SQUENCE_NUM,VECTOR_UNIT)\n",
    "\n",
    "base_network = create_base_network(HID_DIM)\n",
    "\n",
    "input_left = Input(shape=(SQUENCE_NUM,VECTOR_UNIT))\n",
    "input_right = Input(shape=(SQUENCE_NUM,VECTOR_UNIT))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_left = base_network(input_left)\n",
    "processed_right = base_network(input_right)\n",
    "#print(processed_left.shape)\n",
    "#print(processed_left[0].shape)\n",
    "\n",
    "abs_of_sub = Lambda (function = lambda x: abs(x[0] - x[1]), output_shape=lambda x: (x[0], 1))([processed_left,processed_right])\n",
    "\n",
    "###distance = Lambda(Euclidean_distance,output_shape=eucl_dist_output_shape)([processed_left, processed_right])\n",
    "#distance = Lambda(function=lambda x: Euclidean_distance(x[0], x[1]),output_shape=lambda x: (x[0], 1))([processed_left, processed_right])\n",
    "#Dropout(abs_of_sub, 0.5)\n",
    "Dens_layer1 = Dense(64, activation= 'relu', input_dim= 64, use_bias= True)(abs_of_sub)\n",
    "Dens_layer = Dense(1, activation= 'sigmoid', input_dim= 64, use_bias= True)(Dens_layer1)  \n",
    "\n",
    "\n",
    "#model = Model([input_left, input_right], distance)\n",
    "model = Model([input_left, input_right], Dens_layer)\n",
    "abs_predict = Model([input_left, input_right],abs_of_sub)\n",
    "left_predict = Model([input_left, input_right],processed_left)\n",
    "#model2 = Model([input_left, input_right], abs_of_sub)\n",
    "model.load_weights('./64D_Free_text_explaint_step70_epochs100_100batch_size_512_lr000001_same<0.5.h5')\n",
    "#model2.load_weights('./Free_text_Dense_2layers_distance_step70_epochs100_3rd100batch_size_512_lr000001_same_0.5.h5')\n",
    "#model = multi_gpu_model(model,gpus =3)   #用gpu训练\n",
    "\n",
    "model.summary()\n",
    "#model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict([left,right])\n",
    "decision = abs_predict.predict([left,right])\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame(result)\n",
    "df_result.columns = {'output'}\n",
    "df_decision = pd.DataFrame(decision)\n",
    "df_decision.columns = ['v_0','v_1','v_2','v_3','v_4','v_5','v_6','v_7','v_8','v_9','v_10','v_11','v_12','v_13','v_14','v_15','v_16','v_17','v_18','v_19','v_20','v_21','v_22','v_23','v_24','v_25','v_26','v_27','v_28','v_29','v_30','v_31','v_32','v_33','v_34','v_35','v_36','v_37','v_38','v_39','v_40','v_41','v_42','v_43','v_44','v_45','v_46','v_47','v_48','v_49','v_50','v_51','v_52','v_53','v_54','v_55','v_56','v_57','v_58','v_59','v_60','v_61','v_62','v_63']\n",
    "result = pd.concat([new_dataFrame,df_decision,df_result],ignore_index=False, axis = 1)\n",
    "\n",
    "\n",
    "result.to_csv('Free_64D_decision_layer_output_10000user_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'v_0','v_1','v_2','v_3','v_4','v_5','v_6','v_7','v_8','v_9','v_10','v_11','v_12','v_13','v_14','v_15','v_16','v_17','v_18','v_19','v_20','v_21','v_22','v_23','v_24','v_25','v_26','v_27','v_28','v_29','v_30','v_31','v_32','v_33','v_34','v_35','v_36','v_37','v_38','v_39','v_40','v_41','v_42','v_43','v_44','v_45','v_46','v_47','v_48','v_49','v_50','v_51','v_52','v_53','v_54','v_55','v_56','v_57','v_58','v_59','v_60','v_61','v_62','v_63',\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "string = ''\n",
    "\n",
    "for i in range(128):\n",
    "    string += '\\''+str(i)+'\\':'+'\\'v_'+str(i)+'\\','\n",
    "string\n",
    "'''\n",
    "string = ''\n",
    "\n",
    "for i in range(64):\n",
    "    string += '\\'v_'+str(i)+'\\','\n",
    "string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_pred = left_predict.predict([left,right])\n",
    "\n",
    "df_left = pd.DataFrame(left_pred)\n",
    "df_left.columns = ['v_0','v_1','v_2','v_3','v_4','v_5','v_6','v_7','v_8','v_9','v_10','v_11','v_12','v_13','v_14','v_15','v_16','v_17','v_18','v_19','v_20','v_21','v_22','v_23','v_24','v_25','v_26','v_27','v_28','v_29','v_30','v_31','v_32','v_33','v_34','v_35','v_36','v_37','v_38','v_39','v_40','v_41','v_42','v_43','v_44','v_45','v_46','v_47','v_48','v_49','v_50','v_51','v_52','v_53','v_54','v_55','v_56','v_57','v_58','v_59','v_60','v_61','v_62','v_63']\n",
    "result = pd.concat([new_dataFrame,df_left],ignore_index=False, axis = 1)\n",
    "\n",
    "result.to_csv('Free_64D_left_output_10000user_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
